{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6903244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "import google.generativeai as genai\n",
    "# from google import genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a70ae677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaLLM:\n",
    "    \"\"\"Simple wrapper for Ollama API\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, base_url: str = \"http://localhost:11434\"):\n",
    "        self.model = model\n",
    "        self.base_url = base_url\n",
    "    \n",
    "    def generate_content(self, prompt: str) -> str:\n",
    "        \"\"\"Generate content using Ollama\"\"\"\n",
    "        url = f\"{self.base_url}/api/generate\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"temperature\": 0,\n",
    "                \"num_predict\": 500\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(url, json=payload, timeout=120)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            return result.get('response', '')\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e1ee4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Handle vector database operations\"\"\"\n",
    "    \n",
    "    def __init__(self, persist_directory: str, embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.embedding_model = SentenceTransformer(embedding_model)\n",
    "        self.client = chromadb.PersistentClient(path=persist_directory)\n",
    "        self.collection = self.client.get_or_create_collection(name=\"reviews\")\n",
    "    \n",
    "    def search(self, query: str, k: int = 10) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for similar documents\"\"\"\n",
    "        query_embedding = self.embedding_model.encode(query).tolist()\n",
    "        \n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=k\n",
    "        )\n",
    "        \n",
    "        documents = []\n",
    "        if results['documents'] and results['documents'][0]:\n",
    "            for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):\n",
    "                documents.append({\n",
    "                    'content': doc,\n",
    "                    'metadata': metadata\n",
    "                })\n",
    "        \n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89ecd89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsTool:\n",
    "    \"\"\"Tool for answering questions about patient reviews\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, llm):\n",
    "        self.vector_store = vector_store\n",
    "        self.llm = llm\n",
    "        self.name = \"Reviews\"\n",
    "        self.description = \"\"\"Useful when you need to answer questions about patient reviews or experiences at the hospital. \n",
    "                                Not useful for answering questions about specific visit details such as payer, billing, treatment, diagnosis, \n",
    "                                chief complaint, hospital, or physician information. Pass the entire question as input.\"\"\"\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Execute the reviews tool\"\"\"\n",
    "        # Retrieve relevant documents\n",
    "        documents = self.vector_store.search(query, k=10)\n",
    "        \n",
    "        # Format context\n",
    "        context = \"\\n\\n\".join([doc['content'] for doc in documents])\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = f\"\"\"Your job is to use patient reviews to answer questions about their experience at a hospital. \n",
    "                        Use the following context to answer questions. Be as detailed as possible, but don't make up \n",
    "                        any information that's not from the context. If you don't know an answer, say you don't know.\n",
    "\n",
    "                        Context:\n",
    "                        {context}\n",
    "\n",
    "                        Question: {query}\n",
    "\n",
    "                        Answer:\"\"\"\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.llm.generate_content(prompt)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f68f23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaitTimeTool:\n",
    "    \"\"\"Tool for getting current wait times at hospitals\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Waits\"\n",
    "        self.description = \"\"\"Use when asked about current wait times at a specific hospital. \n",
    "                                This tool ONLY accepts the hospital name, like \"A\", \"B\", or \"C\". \n",
    "                                For example: If the question is \"What is the wait time at hospital C?\", input should be \"C\". \n",
    "                                Do NOT include the word \"hospital\" or any other words, only the single letter name.\"\"\"\n",
    "    \n",
    "    def run(self, hospital_name: str) -> int:\n",
    "        \"\"\"Get current wait time for a hospital (simulated)\"\"\"\n",
    "        # Clean the input\n",
    "        hospital_name = hospital_name.strip().upper()\n",
    "        \n",
    "        # Remove \"hospital\" if present\n",
    "        hospital_name = hospital_name.replace(\"HOSPITAL\", \"\").strip()\n",
    "        \n",
    "        # Simulate wait times\n",
    "        wait_times = {\n",
    "            'A': random.randint(10, 60),\n",
    "            'B': random.randint(10, 60),\n",
    "            'C': random.randint(10, 60)\n",
    "        }\n",
    "        \n",
    "        return wait_times.get(hospital_name, \"Unknown hospital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1116bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"Simple ReAct-style agent\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, tools: List[Any], max_iterations: int = 5):\n",
    "        self.llm = llm\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.max_iterations = max_iterations\n",
    "    \n",
    "    def run(self, query: str, verbose: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the agent\"\"\"\n",
    "        intermediate_steps = []\n",
    "        \n",
    "        # Create system prompt\n",
    "        tool_descriptions = \"\\n\".join([\n",
    "            f\"- {name}: {tool.description}\" \n",
    "            for name, tool in self.tools.items()\n",
    "        ])\n",
    "        \n",
    "        system_prompt = f\"\"\"You are a helpful assistant that can use tools to answer questions.\n",
    "\n",
    "                            Available tools:\n",
    "                            {tool_descriptions}\n",
    "\n",
    "                            To use a tool, respond in this EXACT format:\n",
    "                            Thought: [your reasoning]\n",
    "                            Action: [tool name]\n",
    "                            Action Input: [input for the tool]\n",
    "\n",
    "                            When you have the final answer, respond in this EXACT format:\n",
    "                            Thought: I now have enough information to answer\n",
    "                            Final Answer: [your answer]\n",
    "\n",
    "                            Remember: Use ONLY the tool names \"Reviews\" or \"Waits\". Be precise with formatting.\n",
    "\n",
    "                            Begin!\"\"\"\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Build prompt\n",
    "            if iteration == 0:\n",
    "                prompt = f\"{system_prompt}\\n\\nQuestion: {query}\\n\\nThought:\"\n",
    "            else:\n",
    "                prompt = f\"{system_prompt}\\n\\nQuestion: {query}\\n\\n\"\n",
    "                for step in intermediate_steps:\n",
    "                    prompt += f\"Thought: {step['thought']}\\n\"\n",
    "                    prompt += f\"Action: {step['action']}\\n\"\n",
    "                    prompt += f\"Action Input: {step['action_input']}\\n\"\n",
    "                    prompt += f\"Observation: {step['observation']}\\n\\n\"\n",
    "                prompt += \"Thought:\"\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*50}\")\n",
    "                print(f\"Iteration {iteration + 1}\")\n",
    "                print(f\"{'='*50}\")\n",
    "            \n",
    "            # Generate response\n",
    "            response = self.llm.generate_content(prompt)\n",
    "            \n",
    "            # Handle different response types\n",
    "            if hasattr(response, 'text'):\n",
    "                response_text = response.text\n",
    "            else:\n",
    "                response_text = str(response)\n",
    "            \n",
    "            if verbose:\n",
    "                print(response_text)\n",
    "            \n",
    "            # Parse response\n",
    "            if \"Final Answer:\" in response_text:\n",
    "                final_answer = response_text.split(\"Final Answer:\")[-1].strip()\n",
    "                return {\n",
    "                    'input': query,\n",
    "                    'output': final_answer,\n",
    "                    'intermediate_steps': intermediate_steps\n",
    "                }\n",
    "            \n",
    "            # Extract action and action input\n",
    "            try:\n",
    "                thought = response_text.split(\"Action:\")[0].strip()\n",
    "                action_line = response_text.split(\"Action:\")[1].split(\"Action Input:\")[0].strip()\n",
    "                action_input_line = response_text.split(\"Action Input:\")[1].strip()\n",
    "                \n",
    "                # Clean up action input\n",
    "                action_input = action_input_line.replace('\"', '').replace(\"'\", '').strip()\n",
    "                # Remove any text after newlines\n",
    "                if '\\n' in action_input:\n",
    "                    action_input = action_input.split('\\n')[0].strip()\n",
    "                \n",
    "                # Execute tool\n",
    "                if action_line in self.tools:\n",
    "                    observation = self.tools[action_line].run(action_input)\n",
    "                    \n",
    "                    intermediate_steps.append({\n",
    "                        'thought': thought,\n",
    "                        'action': action_line,\n",
    "                        'action_input': action_input,\n",
    "                        'observation': observation\n",
    "                    })\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"\\nObservation: {observation}\")\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"\\nError: Unknown tool '{action_line}'\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"\\nError parsing response: {e}\")\n",
    "                if intermediate_steps:\n",
    "                    return {\n",
    "                        'input': query,\n",
    "                        'output': f\"Based on available information: {intermediate_steps[-1]['observation']}\",\n",
    "                        'intermediate_steps': intermediate_steps\n",
    "                    }\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            'input': query,\n",
    "            'output': \"Could not determine final answer\",\n",
    "            'intermediate_steps': intermediate_steps\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "746d3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing chatbot with Ollama...\n",
      "✓ Chatbot ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing chatbot with Ollama...\")\n",
    "\n",
    "# Initialize Ollama LLM\n",
    "llm = OllamaLLM(model=\"llama3:8b\")\n",
    "\n",
    "# Initialize vector store\n",
    "review_chroma_path = r\"C:\\Users\\noeln\\Desktop\\llm\\20260106_llm_chatbot\\langchain_intro\\chromadb\\chroma_data\"\n",
    "vector_store = VectorStore(persist_directory=review_chroma_path)\n",
    "\n",
    "# Initialize tools\n",
    "reviews_tool = ReviewsTool(vector_store, llm)\n",
    "wait_time_tool = WaitTimeTool()\n",
    "\n",
    "# Initialize agent\n",
    "agent = Agent(llm, tools=[reviews_tool, wait_time_tool])\n",
    "\n",
    "print(\"✓ Chatbot ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d89833e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY 1: Current wait time at hospital C\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "Iteration 1\n",
      "==================================================\n",
      "Thought: The question asks about the current wait time at a specific hospital, and I need to use the \"Waits\" tool to get the answer.\n",
      "Action: Waits\n",
      "Action Input: C\n",
      "\n",
      "Observation: 25\n",
      "\n",
      "==================================================\n",
      "Iteration 2\n",
      "==================================================\n",
      "Thought: The question asks about the current wait time at a specific hospital, and I need to use the \"Waits\" tool to get the answer.\n",
      "Action: Waits\n",
      "Action Input: C\n",
      "\n",
      "Final Answer: 25\n",
      "\n",
      "✓ Final Answer: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUERY 1: Current wait time at hospital C\")\n",
    "print(\"=\"*80)\n",
    "result1 = agent.run(\"What is the current wait time at hospital C?\", verbose=True)\n",
    "print(f\"\\n✓ Final Answer: {result1['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a023579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY 2: Patient comfort reviews\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "Iteration 1\n",
      "==================================================\n",
      "Thought: The question is asking about patient reviews and experiences, which suggests that I should use the Reviews tool to gather information.\n",
      "Action: Reviews\n",
      "Action Input: Pass the entire question as input.\n",
      "\n",
      "Observation: I'm ready to help! Please go ahead and pass the question, and I'll do my best to provide a detailed answer based on patient reviews. If I don't know an answer, I'll let you know that too. Go ahead and ask your question!\n",
      "\n",
      "==================================================\n",
      "Iteration 2\n",
      "==================================================\n",
      "Thought: The question is asking about patient reviews and experiences, which suggests that I should use the Reviews tool to gather information.\n",
      "Action: Reviews\n",
      "Action Input: What have patients said about their comfort at the hospital?\n",
      "\n",
      "Observation: Based on patient reviews, many patients have commented positively about their comfort during their stay at the hospital. Some reviewers have mentioned that the hospital's beds are comfortable and provide adequate support for a good night's sleep. One reviewer even noted that they were able to get a good night's rest despite having a painful injury.\n",
      "\n",
      "Additionally, some patients have praised the hospital's efforts to keep them warm and cozy during their stay. For example, one reviewer mentioned that the hospital provided extra blankets and pillows to ensure they stayed comfortable throughout the night.\n",
      "\n",
      "However, not all patients have had positive experiences with comfort at the hospital. Some reviewers have reported feeling cold or uncomfortable due to issues with room temperature or inadequate bedding. One reviewer even mentioned that they were given a thin blanket that didn't provide enough warmth during their stay.\n",
      "\n",
      "Overall, while some patients have reported mixed experiences with comfort at the hospital, many have praised the efforts of staff and facilities to ensure their comfort and well-being during their stay.\n",
      "\n",
      "==================================================\n",
      "Iteration 3\n",
      "==================================================\n",
      "I now have enough information to answer!\n",
      "\n",
      "Final Answer: Based on patient reviews, many patients have commented positively about their comfort during their stay at the hospital. Some reviewers have mentioned that the hospital's beds are comfortable and provide adequate support for a good night's sleep. However, not all patients have had positive experiences with comfort at the hospital, with some reporting feeling cold or uncomfortable due to issues with room temperature or inadequate bedding.\n",
      "\n",
      "✓ Final Answer: Based on patient reviews, many patients have commented positively about their comfort during their stay at the hospital. Some reviewers have mentioned that the hospital's beds are comfortable and provide adequate support for a good night's sleep. However, not all patients have had positive experiences with comfort at the hospital, with some reporting feeling cold or uncomfortable due to issues with room temperature or inadequate bedding.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUERY 2: Patient comfort reviews\")\n",
    "print(\"=\"*80)\n",
    "result2 = agent.run(\"What have patients said about their comfort at the hospital?\", verbose=True)\n",
    "print(f\"\\n✓ Final Answer: {result2['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8439ff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY 3: Random Questions\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "Iteration 1\n",
      "==================================================\n",
      "Thought: The question seems to be asking two unrelated things, one about demographics (population of Malaysia) and another about math (3+5). I'll need to use a tool to answer each part separately.\n",
      "\n",
      "Action: Reviews\n",
      "Action Input: None (this question doesn't require the \"Reviews\" tool)\n",
      "\n",
      "Let's see if there are any other tools that can help with the math part.\n",
      "\n",
      "Observation: I'm ready to help! Since there is no specific question yet, I'll wait for one to be asked. Please go ahead and ask your question about a patient's experience at a hospital, and I'll do my best to provide a detailed answer based on the provided context. If I don't know an answer, I'll let you know that too!\n",
      "\n",
      "==================================================\n",
      "Iteration 2\n",
      "==================================================\n",
      "Thought: The question is asking for two different types of information - population of Malaysia and math calculation (3+5). Since there's no specific hospital or patient experience mentioned, I won't be able to use the \"Reviews\" tool. Instead, I'll need to find another way to answer the first part of the question.\n",
      "Action: None\n",
      "Action Input: None\n",
      "\n",
      "Please proceed with asking a new question!\n",
      "\n",
      "Error: Unknown tool 'None'\n",
      "\n",
      "✓ Final Answer: Could not determine final answer\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUERY 3: Random Question\")\n",
    "print(\"=\"*80)\n",
    "result3 = agent.run(\"What is the population of Malaysia and how many is 3 + 5?\", verbose=True)\n",
    "print(f\"\\n✓ Final Answer: {result3['output']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_chatbot",
   "language": "python",
   "name": "llm_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
